------------ Options -------------
batchSize: 1
beta1: 0.5
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: ./datasets/bolbbalgan4
dataset_mode: aligned
display_freq: 100
display_id: 1
display_port: 8097
display_single_pane_ncols: 0
display_winsize: 256
epoch_count: 1
fineSize: 1024
gpu_ids: [0]
identity: 0.5
init_type: xavier
input_nc: 1
isTrain: True
lambda_A: 10.0
lambda_B: 10.0
loadSize: 1
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: 5000
model: cycle_gan
nThreads: 4
n_layers_D: 3
name: experiment_name
ndf: 64
ngf: 64
niter: 100
niter_decay: 100
no_dropout: False
no_flip: False
no_html: False
no_lsgan: False
norm: instance
output_nc: 1
phase: train
pool_size: 10
print_freq: 100
resize_or_crop: resize_and_crop
save_epoch_freq: 5
save_latest_freq: 5000
serial_batches: True
update_html_freq: 1000
which_direction: AtoB
which_epoch: latest
which_model_netD: basic
which_model_netG: resnet_9blocks
-------------- End ----------------
CustomDatasetDataLoader
dataset [AlignedDataset] was created
#training images = 0
cycle_gan
initialization method [xavier]
initialization method [xavier]
initialization method [xavier]
initialization method [xavier]
---------- Networks initialized -------------
ResnetGenerator(
  (model): Sequential(
    (0): ReflectionPad2d((3, 3, 3, 3))
    (1): Conv2d (1, 64, kernel_size=(7, 7), stride=(1, 1))
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)
    (3): ReLU(inplace)
    (4): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (6): ReLU(inplace)
    (7): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
    (9): ReLU(inplace)
    (10): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (11): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (12): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (13): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (14): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (15): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (16): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (17): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (18): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (19): ConvTranspose2d (256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (21): ReLU(inplace)
    (22): ConvTranspose2d (128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)
    (24): ReLU(inplace)
    (25): ReflectionPad2d((3, 3, 3, 3))
    (26): Conv2d (64, 1, kernel_size=(7, 7), stride=(1, 1))
    (27): Tanh()
  )
)
Total number of parameters: 11365633
ResnetGenerator(
  (model): Sequential(
    (0): ReflectionPad2d((3, 3, 3, 3))
    (1): Conv2d (1, 64, kernel_size=(7, 7), stride=(1, 1))
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)
    (3): ReLU(inplace)
    (4): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (6): ReLU(inplace)
    (7): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
    (9): ReLU(inplace)
    (10): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (11): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (12): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (13): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (14): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (15): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (16): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (17): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (18): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
        (3): ReLU(inplace)
        (4): Dropout(p=0.5)
        (5): ReflectionPad2d((1, 1, 1, 1))
        (6): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
        (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
      )
    )
    (19): ConvTranspose2d (256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (21): ReLU(inplace)
    (22): ConvTranspose2d (128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)
    (24): ReLU(inplace)
    (25): ReflectionPad2d((3, 3, 3, 3))
    (26): Conv2d (64, 1, kernel_size=(7, 7), stride=(1, 1))
    (27): Tanh()
  )
)
Total number of parameters: 11365633
NLayerDiscriminator(
  (model): Sequential(
    (0): Conv2d (1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(0.2, inplace)
    (2): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (4): LeakyReLU(0.2, inplace)
    (5): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
    (7): LeakyReLU(0.2, inplace)
    (8): Conv2d (256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False)
    (10): LeakyReLU(0.2, inplace)
    (11): Conv2d (512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
  )
)
Total number of parameters: 2762689
NLayerDiscriminator(
  (model): Sequential(
    (0): Conv2d (1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(0.2, inplace)
    (2): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)
    (4): LeakyReLU(0.2, inplace)
    (5): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)
    (7): LeakyReLU(0.2, inplace)
    (8): Conv2d (256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False)
    (10): LeakyReLU(0.2, inplace)
    (11): Conv2d (512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
  )
)
Total number of parameters: 2762689
-----------------------------------------------
model [CycleGANModel] was created
create web directory ./checkpoints/experiment_name/web...
End of epoch 1 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 2 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 3 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 4 / 200     Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 5, iters 0
End of epoch 5 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 6 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 7 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 8 / 200     Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 9 / 200     Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 10, iters 0
End of epoch 10 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 11 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 12 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 13 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 14 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 15, iters 0
End of epoch 15 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 16 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 17 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 18 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 19 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 20, iters 0
End of epoch 20 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 21 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 22 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 23 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 24 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 25, iters 0
End of epoch 25 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 26 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 27 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 28 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 29 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 30, iters 0
End of epoch 30 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 31 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 32 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 33 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 34 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 35, iters 0
End of epoch 35 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 36 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 37 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 38 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 39 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 40, iters 0
End of epoch 40 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 41 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 42 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 43 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 44 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 45, iters 0
End of epoch 45 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 46 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 47 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 48 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 49 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 50, iters 0
End of epoch 50 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 51 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 52 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 53 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 54 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 55, iters 0
End of epoch 55 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 56 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 57 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 58 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 59 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 60, iters 0
End of epoch 60 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 61 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 62 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 63 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 64 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 65, iters 0
End of epoch 65 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 66 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 67 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 68 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 69 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 70, iters 0
End of epoch 70 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 71 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 72 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 73 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 74 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 75, iters 0
End of epoch 75 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 76 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 77 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 78 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 79 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 80, iters 0
End of epoch 80 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 81 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 82 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 83 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 84 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 85, iters 0
End of epoch 85 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 86 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 87 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 88 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 89 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 90, iters 0
End of epoch 90 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 91 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 92 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 93 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 94 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 95, iters 0
End of epoch 95 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 96 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 97 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 98 / 200    Time Taken: 0 sec
learning rate = 0.0002000
End of epoch 99 / 200    Time Taken: 0 sec
learning rate = 0.0002000
saving the model at the end of epoch 100, iters 0
End of epoch 100 / 200   Time Taken: 0 sec
learning rate = 0.0001980
End of epoch 101 / 200   Time Taken: 0 sec
learning rate = 0.0001960
End of epoch 102 / 200   Time Taken: 0 sec
learning rate = 0.0001941
End of epoch 103 / 200   Time Taken: 0 sec
learning rate = 0.0001921
End of epoch 104 / 200   Time Taken: 0 sec
learning rate = 0.0001901
saving the model at the end of epoch 105, iters 0
End of epoch 105 / 200   Time Taken: 0 sec
learning rate = 0.0001881
End of epoch 106 / 200   Time Taken: 0 sec
learning rate = 0.0001861
End of epoch 107 / 200   Time Taken: 0 sec
learning rate = 0.0001842
End of epoch 108 / 200   Time Taken: 0 sec
learning rate = 0.0001822
End of epoch 109 / 200   Time Taken: 0 sec
learning rate = 0.0001802
saving the model at the end of epoch 110, iters 0
End of epoch 110 / 200   Time Taken: 1 sec
learning rate = 0.0001782
End of epoch 111 / 200   Time Taken: 0 sec
learning rate = 0.0001762
End of epoch 112 / 200   Time Taken: 0 sec
learning rate = 0.0001743
End of epoch 113 / 200   Time Taken: 0 sec
learning rate = 0.0001723
End of epoch 114 / 200   Time Taken: 0 sec
learning rate = 0.0001703
saving the model at the end of epoch 115, iters 0
End of epoch 115 / 200   Time Taken: 1 sec
learning rate = 0.0001683
End of epoch 116 / 200   Time Taken: 0 sec
learning rate = 0.0001663
End of epoch 117 / 200   Time Taken: 0 sec
learning rate = 0.0001644
End of epoch 118 / 200   Time Taken: 0 sec
learning rate = 0.0001624
End of epoch 119 / 200   Time Taken: 0 sec
learning rate = 0.0001604
saving the model at the end of epoch 120, iters 0
End of epoch 120 / 200   Time Taken: 1 sec
learning rate = 0.0001584
End of epoch 121 / 200   Time Taken: 0 sec
learning rate = 0.0001564
End of epoch 122 / 200   Time Taken: 0 sec
learning rate = 0.0001545
End of epoch 123 / 200   Time Taken: 0 sec
learning rate = 0.0001525
End of epoch 124 / 200   Time Taken: 0 sec
learning rate = 0.0001505
saving the model at the end of epoch 125, iters 0
End of epoch 125 / 200   Time Taken: 1 sec
learning rate = 0.0001485
End of epoch 126 / 200   Time Taken: 0 sec
learning rate = 0.0001465
End of epoch 127 / 200   Time Taken: 0 sec
learning rate = 0.0001446
End of epoch 128 / 200   Time Taken: 0 sec
learning rate = 0.0001426
End of epoch 129 / 200   Time Taken: 0 sec
learning rate = 0.0001406
saving the model at the end of epoch 130, iters 0
End of epoch 130 / 200   Time Taken: 1 sec
learning rate = 0.0001386
End of epoch 131 / 200   Time Taken: 0 sec
learning rate = 0.0001366
End of epoch 132 / 200   Time Taken: 0 sec
learning rate = 0.0001347
End of epoch 133 / 200   Time Taken: 0 sec
learning rate = 0.0001327
End of epoch 134 / 200   Time Taken: 0 sec
learning rate = 0.0001307
saving the model at the end of epoch 135, iters 0
End of epoch 135 / 200   Time Taken: 0 sec
learning rate = 0.0001287
End of epoch 136 / 200   Time Taken: 0 sec
learning rate = 0.0001267
End of epoch 137 / 200   Time Taken: 0 sec
learning rate = 0.0001248
End of epoch 138 / 200   Time Taken: 0 sec
learning rate = 0.0001228
End of epoch 139 / 200   Time Taken: 0 sec
learning rate = 0.0001208
saving the model at the end of epoch 140, iters 0
End of epoch 140 / 200   Time Taken: 0 sec
learning rate = 0.0001188
End of epoch 141 / 200   Time Taken: 0 sec
learning rate = 0.0001168
End of epoch 142 / 200   Time Taken: 0 sec
learning rate = 0.0001149
End of epoch 143 / 200   Time Taken: 0 sec
learning rate = 0.0001129
End of epoch 144 / 200   Time Taken: 0 sec
learning rate = 0.0001109
saving the model at the end of epoch 145, iters 0
End of epoch 145 / 200   Time Taken: 0 sec
learning rate = 0.0001089
End of epoch 146 / 200   Time Taken: 0 sec
learning rate = 0.0001069
End of epoch 147 / 200   Time Taken: 0 sec
learning rate = 0.0001050
End of epoch 148 / 200   Time Taken: 0 sec
learning rate = 0.0001030
End of epoch 149 / 200   Time Taken: 0 sec
learning rate = 0.0001010
saving the model at the end of epoch 150, iters 0
End of epoch 150 / 200   Time Taken: 0 sec
learning rate = 0.0000990
End of epoch 151 / 200   Time Taken: 0 sec
learning rate = 0.0000970
End of epoch 152 / 200   Time Taken: 0 sec
learning rate = 0.0000950
End of epoch 153 / 200   Time Taken: 0 sec
learning rate = 0.0000931
End of epoch 154 / 200   Time Taken: 0 sec
learning rate = 0.0000911
saving the model at the end of epoch 155, iters 0
End of epoch 155 / 200   Time Taken: 0 sec
learning rate = 0.0000891
End of epoch 156 / 200   Time Taken: 0 sec
learning rate = 0.0000871
End of epoch 157 / 200   Time Taken: 0 sec
learning rate = 0.0000851
End of epoch 158 / 200   Time Taken: 0 sec
learning rate = 0.0000832
End of epoch 159 / 200   Time Taken: 0 sec
learning rate = 0.0000812
saving the model at the end of epoch 160, iters 0
End of epoch 160 / 200   Time Taken: 0 sec
learning rate = 0.0000792
End of epoch 161 / 200   Time Taken: 0 sec
learning rate = 0.0000772
End of epoch 162 / 200   Time Taken: 0 sec
learning rate = 0.0000752
End of epoch 163 / 200   Time Taken: 0 sec
learning rate = 0.0000733
End of epoch 164 / 200   Time Taken: 0 sec
learning rate = 0.0000713
saving the model at the end of epoch 165, iters 0
End of epoch 165 / 200   Time Taken: 0 sec
learning rate = 0.0000693
End of epoch 166 / 200   Time Taken: 0 sec
learning rate = 0.0000673
End of epoch 167 / 200   Time Taken: 0 sec
learning rate = 0.0000653
End of epoch 168 / 200   Time Taken: 0 sec
learning rate = 0.0000634
End of epoch 169 / 200   Time Taken: 0 sec
learning rate = 0.0000614
saving the model at the end of epoch 170, iters 0
End of epoch 170 / 200   Time Taken: 0 sec
learning rate = 0.0000594
End of epoch 171 / 200   Time Taken: 0 sec
learning rate = 0.0000574
End of epoch 172 / 200   Time Taken: 0 sec
learning rate = 0.0000554
End of epoch 173 / 200   Time Taken: 0 sec
learning rate = 0.0000535
End of epoch 174 / 200   Time Taken: 0 sec
learning rate = 0.0000515
saving the model at the end of epoch 175, iters 0
End of epoch 175 / 200   Time Taken: 0 sec
learning rate = 0.0000495
End of epoch 176 / 200   Time Taken: 0 sec
learning rate = 0.0000475
End of epoch 177 / 200   Time Taken: 0 sec
learning rate = 0.0000455
End of epoch 178 / 200   Time Taken: 0 sec
learning rate = 0.0000436
End of epoch 179 / 200   Time Taken: 0 sec
learning rate = 0.0000416
saving the model at the end of epoch 180, iters 0
End of epoch 180 / 200   Time Taken: 0 sec
learning rate = 0.0000396
End of epoch 181 / 200   Time Taken: 0 sec
learning rate = 0.0000376
End of epoch 182 / 200   Time Taken: 0 sec
learning rate = 0.0000356
End of epoch 183 / 200   Time Taken: 0 sec
learning rate = 0.0000337
End of epoch 184 / 200   Time Taken: 0 sec
learning rate = 0.0000317
saving the model at the end of epoch 185, iters 0
End of epoch 185 / 200   Time Taken: 0 sec
learning rate = 0.0000297
End of epoch 186 / 200   Time Taken: 0 sec
learning rate = 0.0000277
End of epoch 187 / 200   Time Taken: 0 sec
learning rate = 0.0000257
End of epoch 188 / 200   Time Taken: 0 sec
learning rate = 0.0000238
End of epoch 189 / 200   Time Taken: 0 sec
learning rate = 0.0000218
saving the model at the end of epoch 190, iters 0
End of epoch 190 / 200   Time Taken: 1 sec
learning rate = 0.0000198
End of epoch 191 / 200   Time Taken: 0 sec
learning rate = 0.0000178
End of epoch 192 / 200   Time Taken: 0 sec
learning rate = 0.0000158
End of epoch 193 / 200   Time Taken: 0 sec
learning rate = 0.0000139
End of epoch 194 / 200   Time Taken: 0 sec
learning rate = 0.0000119
saving the model at the end of epoch 195, iters 0
End of epoch 195 / 200   Time Taken: 1 sec
learning rate = 0.0000099
End of epoch 196 / 200   Time Taken: 0 sec
learning rate = 0.0000079
End of epoch 197 / 200   Time Taken: 0 sec
learning rate = 0.0000059
End of epoch 198 / 200   Time Taken: 0 sec
learning rate = 0.0000040
End of epoch 199 / 200   Time Taken: 0 sec
learning rate = 0.0000020
saving the model at the end of epoch 200, iters 0
End of epoch 200 / 200   Time Taken: 1 sec
learning rate = 0.0000000
